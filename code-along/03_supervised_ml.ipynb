{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning\n",
    "\n",
    "This notebook demonstrates a streamlined classical machine learning (ML). We will build a selection of models, using multiple algorithms and techniques, and compare their performance. As in the [previous episode](1_data_explore.ipynb), the dataset we will be using is the [Indian Liver Patient Dataset](https://www.kaggle.com/datasets/jeevannagaraj/indian-liver-patient-dataset).\n",
    "\n",
    "## Key Objectives\n",
    "- Apply **multiple classical ML algorithms**\n",
    "- Perform **feature selection** and **preprocessing**\n",
    "- Use **cross-validation** and **hyperparameter tuning**\n",
    "- Compare model **performance** and **interpretability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Packages and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn essentials\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Classical ML algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the augmented data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "A reminder of the shape and distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View that shape, see if any missing values snuck in, and how the data is distributed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Analysis & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data from the target column\n",
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data with test_train_split\n",
    "X_train, X_test, y_train, y_test = \n",
    "\n",
    "# Scale the features with StandardScalar\n",
    "scaler = \n",
    "X_train_scaled = \n",
    "X_test_scaled = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cross validation cross validation](../assets/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models in a dictionary:\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to train and predict with a model\n",
    "\n",
    "# intialise model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# train the model with .fit()\n",
    "\n",
    "# predict on new data with .predict()\n",
    "\n",
    "# get the probability with .predict_proba()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through, train and evaluate each model:\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "    else: \n",
    "        None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    if y_pred_proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba) \n",
    "    else:\n",
    "        None\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_score = cross_val_score(model, X_train_selected, y_train, cv=5, scoring='accuracy').mean()\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'CV Score': cv_score\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Scores diagram](../assets/Confusion-matrix-Precision-Recall-Accuracy-and-F1-score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. Model Comparison & Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise model performance:\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy comparison:\n",
    "axes[0, 0].bar(results_df.index, results_df['CV Score'], color='skyblue')\n",
    "axes[0, 0].set_title('Model Accuracy (CV) Comparison')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "\n",
    "# F1-Score comparison:\n",
    "axes[0, 1].bar(results_df.index, results_df['F1-Score'], color='lightgreen')\n",
    "axes[0, 1].set_title('F1-Score Comparison')\n",
    "axes[0, 1].set_ylabel('F1-Score')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "\n",
    "# Generate line indicating random:\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "\n",
    "# Loop through models :\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    # Get probability predictions:\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_proba = model.decision_function(X_test_selected)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Calculate ROC curve:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    \n",
    "    # Plot:\n",
    "    axes[1, 0].plot(fpr, tpr, label=f'{model_name} (AUC = {results[model_name]['ROC-AUC']:.3f})')\n",
    "\n",
    "axes[1, 0].set_xlabel('False Positive Rate')\n",
    "axes[1, 0].set_ylabel('True Positive Rate')\n",
    "axes[1, 0].set_title('ROC Curves Comparison')\n",
    "axes[1, 0].legend(loc='lower right')\n",
    "axes[1, 0].set_xlim([0.0, 1.0])\n",
    "axes[1, 0].set_ylim([0.0, 1.05])\n",
    "\n",
    "# Overall metrics heatmap:\n",
    "metrics_heatmap = results_df[['CV Score', 'Precision', 'Recall', 'F1-Score']]\n",
    "sns.heatmap(metrics_heatmap, annot=True, cmap='Blues', fmt='.3f', ax=axes[1, 1]) # vmax = 1, vmin = 0,\n",
    "axes[1, 1].set_title('Performance Metrics Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why do some have zero precision and recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understanding the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions from the Random Forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities for class 1 with Random Forest\n",
    "\n",
    "y_proba = \n",
    "\n",
    "print(y_proba)\n",
    "\n",
    "print(f\"Lowest prediction probability: {min(y_proba)}\")\n",
    "\n",
    "print(f\"Highest prediction probability: {max(y_proba)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making our own binary threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "for thresh in thresholds:\n",
    "\n",
    "    # Get the classification given the threshold\n",
    "    y_pred_thresh = (y_proba >= thresh).astype(int)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_thresh)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Calculate TPR and FPR \n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "    \n",
    "    print(f\"\\nThreshold = {thresh}:\")\n",
    "    print(f\"  True Positive Rate: {tpr:.3f}\")\n",
    "    print(f\"  False Positive Rate: {fpr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning - Refining your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model Pythonically:\n",
    "best_model_name = \n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "print(f\"'CV Accuracy: {results_df.loc[best_model_name, 'CV Score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some given hyperparameters, check out their documentation pages for what they so and their normal range:\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    best_model = RandomForestClassifier(random_state=42)\n",
    "elif best_model_name == 'SVM':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 'auto', 0.1, 1],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "    best_model = SVC(random_state=42, probability=True)\n",
    "elif best_model_name == 'Logistic Regression':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    }\n",
    "    best_model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search:\n",
    "grid_search = \n",
    "\n",
    "\n",
    "print(f\"Best parameters for {best_model_name}:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation:\n",
    "final_model = \n",
    "final_predictions = \n",
    "final_accuracy = \n",
    "\n",
    "print(f\"\\nFinal optimised model accuracy: {final_accuracy:.3f}\")\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, final_predictions, target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise model performance:\n",
    "fig, axes = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Generate line indicating random:\n",
    "axes.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "\n",
    "y_proba = final_model.predict_proba(X_test_selected)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "axes.plot(fpr, tpr, label=f'{'Tuned Model'} (AUC = {roc_auc_score(y_test, y_proba):.3f})')\n",
    "\n",
    "base_model = RandomForestClassifier(random_state=42).fit(X_train_selected, y_train)\n",
    "y_proba = base_model.predict_proba(X_test_selected)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "axes.plot(fpr, tpr, label=f'{'Base Model'} (AUC = {roc_auc_score(y_test, y_proba):.3f})')\n",
    "\n",
    "axes.set_xlabel('False Positive Rate')\n",
    "axes.set_ylabel('True Positive Rate')\n",
    "axes.set_title('ROC Curves Comparison')\n",
    "axes.legend(loc='lower right')\n",
    "axes.set_xlim([0.0, 1.0])\n",
    "axes.set_ylim([0.0, 1.05])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Models explained\n",
    "\n",
    "This table summarises the models we built here.\n",
    "\n",
    "| **Model** | **How it Works** | **Pros** | **Cons** |\n",
    "|-----------|------------------|----------|----------|\n",
    "| **Logistic Regression** | Fits a linear equation to the features and applies a **sigmoid** to predict probability of class membership. Learns coefficients that describe how each feature affects log-odds of outcome. | - Very fast and interpretable<br>- Produces probabilities<br>- Works well on linearly separable problems | - Only linear boundaries<br>- Sensitive to multicollinearity<br>- Limited with complex feature interactions |\n",
    "| **Random Forest** | An **ensemble of decision trees** trained on bootstrapped subsets of the data and features. Prediction = majority vote (classification). | - Handles non-linearities<br>- Robust to noise/outliers<br>- Works well without scaling<br>- Provides feature importance | - Can be slower on very large datasets<br>- Less interpretable<br>- May overfit if trees are deep |\n",
    "| **Support Vector Machine (SVM)** | Finds a **hyperplane** that maximises the margin between classes. With kernels, can model non-linear decision boundaries. | - Effective in high-dimensional spaces<br>- Works well with clear margin separation<br>- Flexible with kernels | - Sensitive to parameter choice<br>- Can be slower on larger datasets<br>- Harder to interpret |\n",
    "| **K-Nearest Neighbours (KNN)** | Classifies a new point by looking at the **majority class of its k nearest neighbours** in feature space. | - Simple, intuitive<br>- No training phase<br>- Captures local structure | - Slow at prediction on larger datasets<br>- Sensitive to scaling and irrelevant features<br>- Struggles in high dimensions |\n",
    "| **Gradient Boosting** | Builds an **ensemble of weak learners (shallow trees)** sequentially, where each tree corrects errors of the previous. | - High accuracy<br>- Captures complex patterns<br>- Robust with tuning | - Computationally intensive<br>- Sensitive to hyperparameters<br>- Can overfit small datasets |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2d-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
